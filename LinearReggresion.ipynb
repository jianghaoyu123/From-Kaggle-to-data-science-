{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.使用梯度下降求解\n",
    "$\\mathrm{L}=\\left(\\theta_{1}-3\\right)^{2}+\\left(2 \\theta_{2}-5\\right)^{2}$的最小值点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6000000000000001 2.0\n",
      "1.08 2.4\n",
      "1.464 2.48\n",
      "1.7711999999999999 2.496\n",
      "2.01696 2.4992\n",
      "2.213568 2.49984\n",
      "2.3708544 2.499968\n",
      "2.49668352 2.4999936\n",
      "2.597346816 2.49999872\n",
      "2.6778774528 2.499999744\n",
      "2.74230196224 2.4999999488\n",
      "2.793841569792 2.49999998976\n",
      "2.8350732558336 2.499999997952\n",
      "2.86805860466688 2.4999999995904\n",
      "2.894446883733504 2.49999999991808\n",
      "2.9155575069868034 2.499999999983616\n",
      "2.932446005589443 2.499999999996723\n",
      "2.945956804471554 2.4999999999993445\n",
      "2.9567654435772432 2.499999999999869\n",
      "2.9654123548617948 2.499999999999974\n",
      "2.9723298838894356 2.4999999999999947\n",
      "2.9778639071115487 2.499999999999999\n",
      "2.982291125689239 2.5\n",
      "2.985832900551391 2.5\n",
      "2.988666320441113 2.5\n",
      "2.9909330563528904 2.5\n",
      "2.9927464450823122 2.5\n",
      "2.99419715606585 2.5\n",
      "2.99535772485268 2.5\n",
      "2.996286179882144 2.5\n",
      "2.997028943905715 2.5\n",
      "2.9976231551245722 2.5\n",
      "2.9980985240996576 2.5\n",
      "2.9984788192797263 2.5\n",
      "2.998783055423781 2.5\n",
      "2.999026444339025 2.5\n",
      "2.99922115547122 2.5\n",
      "2.9993769243769757 2.5\n",
      "2.9995015395015807 2.5\n",
      "2.9996012316012646 2.5\n",
      "2.9996809852810116 2.5\n",
      "2.999744788224809 2.5\n",
      "2.9997958305798473 2.5\n",
      "2.999836664463878 2.5\n",
      "2.9998693315711025 2.5\n",
      "2.999895465256882 2.5\n",
      "2.9999163722055053 2.5\n",
      "2.999933097764404 2.5\n",
      "2.9999464782115233 2.5\n",
      "2.9999571825692186 2.5\n",
      "2.999965746055375 2.5\n",
      "2.9999725968443 2.5\n",
      "2.99997807747544 2.5\n",
      "2.999982461980352 2.5\n",
      "2.9999859695842814 2.5\n",
      "2.999988775667425 2.5\n",
      "2.99999102053394 2.5\n",
      "2.999992816427152 2.5\n",
      "2.9999942531417214 2.5\n",
      "2.999995402513377 2.5\n",
      "2.9999963220107015 2.5\n",
      "2.999997057608561 2.5\n",
      "2.999997646086849 2.5\n",
      "2.999998116869479 2.5\n",
      "2.9999984934955832 2.5\n",
      "2.9999987947964666 2.5\n",
      "2.999999035837173 2.5\n",
      "2.9999992286697386 2.5\n",
      "2.999999382935791 2.5\n",
      "2.9999995063486327 2.5\n",
      "2.999999605078906 2.5\n",
      "2.9999996840631247 2.5\n",
      "2.9999997472504996 2.5\n",
      "2.9999997978004 2.5\n",
      "2.9999998382403197 2.5\n",
      "2.999999870592256 2.5\n",
      "2.999999896473805 2.5\n",
      "2.9999999171790437 2.5\n",
      "2.999999933743235 2.5\n",
      "2.999999946994588 2.5\n",
      "2.99999995759567 2.5\n",
      "2.999999966076536 2.5\n",
      "2.9999999728612288 2.5\n",
      "2.999999978288983 2.5\n",
      "2.9999999826311865 2.5\n",
      "2.999999986104949 2.5\n",
      "2.9999999888839595 2.5\n",
      "2.9999999911071678 2.5\n",
      "2.9999999928857344 2.5\n",
      "2.9999999943085873 2.5\n",
      "2.9999999954468697 2.5\n",
      "2.999999996357496 2.5\n",
      "2.9999999970859967 2.5\n",
      "2.999999997668797 2.5\n",
      "2.9999999981350376 2.5\n",
      "2.99999999850803 2.5\n",
      "2.999999998806424 2.5\n",
      "2.9999999990451394 2.5\n",
      "2.9999999992361115 2.5\n",
      "2.9999999993888893 2.5\n"
     ]
    }
   ],
   "source": [
    "theta1 , theta2 = 0.0,0.0\n",
    "alpha = 0.1\n",
    "for i in range(100):\n",
    "    theta1 = theta1 - alpha*2*(theta1-3)\n",
    "    theta2 = theta2 - alpha*2*(2*theta2 -5)*2\n",
    "    print(theta1,theta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 使用梯度下降求解\n",
    "$\\mathrm{L}=\\left(\\theta_{1}-3\\right)^{2}\\left(2 \\theta_{2}-5\\right)^{2}$的最小值点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.74 0.04628800000000011\n",
      "5.975293375748915 1.783981451662664\n",
      "5.85326289340646 2.2503162634613827\n",
      "5.839032651420127 2.411314462006146\n",
      "5.8372463037651885 2.4684277114229185\n",
      "5.837020048260971 2.4887569381894847\n",
      "5.836991358852866 2.49599613879014\n",
      "5.836987720489843 2.498574144730124\n",
      "5.836987259067804 2.4994922240457913\n",
      "5.836987200549514 2.499819170679976\n",
      "5.8369871931281265 2.499935603009519\n",
      "5.836987192186934 2.499977066924836\n",
      "5.83698719206757 2.499991833066536\n",
      "5.836987192052432 2.4999970915892553\n",
      "5.836987192050512 2.4999989642559113\n",
      "5.836987192050269 2.499999631150511\n",
      "5.836987192050238 2.4999998686452116\n",
      "5.836987192050234 2.499999953221894\n",
      "5.836987192050233 2.4999999833413673\n",
      "5.836987192050233 2.499999994067523\n",
      "5.836987192050233 2.4999999978873246\n",
      "5.836987192050233 2.4999999992476334\n",
      "5.836987192050233 2.4999999997320668\n",
      "5.836987192050233 2.4999999999045834\n",
      "5.836987192050233 2.49999999996602\n",
      "5.836987192050233 2.499999999987899\n",
      "5.836987192050233 2.4999999999956906\n",
      "5.836987192050233 2.4999999999984652\n",
      "5.836987192050233 2.4999999999994533\n",
      "5.836987192050233 2.4999999999998055\n",
      "5.836987192050233 2.4999999999999307\n",
      "5.836987192050233 2.499999999999975\n",
      "5.836987192050233 2.499999999999991\n",
      "5.836987192050233 2.499999999999997\n",
      "5.836987192050233 2.499999999999999\n",
      "5.836987192050233 2.4999999999999996\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n",
      "5.836987192050233 2.5\n"
     ]
    }
   ],
   "source": [
    "theta1 , theta2 = 10.0,4.0\n",
    "alpha = 0.01\n",
    "for i in range(100):\n",
    "    theta1 = theta1 - alpha*2*(theta1-3)*(2*theta2-5)*(2*theta2-5)\n",
    "    theta2 = theta2 - alpha*2*(2*theta2 -5)*2*(theta1-3)*(theta1-3)\n",
    "    print(theta1,theta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 使用梯度下降实现最小二乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearRegression(X,y,alpha,n_rounds):\n",
    "    n_features = X.shape[1]\n",
    "    beta = np.array([0.0]*n_features)\n",
    "    for i in range(n_rounds):\n",
    "        \n",
    "        #计算 epsilon\n",
    "        epsilon = y\n",
    "        for j in range(n_features):\n",
    "            epsilon = epsilon - beta[j]*X[:,j]\n",
    "            \n",
    "        #更新 beta\n",
    "        for j in range(n_features):\n",
    "            gradient = -np.mean(epsilon*X[:,j])\n",
    "            beta[j] = beta[j] - alpha*gradient\n",
    "\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24430801, 0.25516176, 0.10030543, 0.81107587])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 确认实现的LinearRegression函数得到的结果与sklearn中的LinearRegression的结果相同\n",
    "data = pd.read_csv('height_train.csv')\n",
    "data['constant'] = 1\n",
    "LinearRegression(data.loc[:,['father_height','mother_height','boy_dummy','constant']].values,data.child_height.values,0.1,100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作业： 实现线性回归的代码，发布到各人Github\n",
    "\n",
    "选作：\n",
    "1. 收敛条件的判断\n",
    "2. 学习率的选择\n",
    "3. 类的形式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作业部分：一、线性回归标准代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('height_train.csv')\n",
    "# set X (training data) and y (target variable)\n",
    "cols = data.shape[1]\n",
    "X = data.iloc[:,1:cols-1]#X是所有行，去掉最后一列\n",
    "y = data.iloc[:,cols-1:cols]#X是所有行，最后一列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "tem=int(X.shape[1]+1)\n",
    "X=np.c_[X,np.ones(y.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.ones((tem,1))\n",
    "alpha=0.001\n",
    "iters=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(X, y, theta):\n",
    "    m=y.shape[0]\n",
    "    thetatem=np.array(theta)\n",
    "    return np.sum((X.dot(theta)-y)**2)/2/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X, y, theta, alpha, iters):\n",
    "  #  temp = np.array(np.zeros(theta.shape))\n",
    "  #  parameters = int(theta.ravel().shape[0])\n",
    "    cost = np.zeros(iters)\n",
    "    m=y.shape[0]\n",
    "    for i in range(iters):\n",
    "        theta=theta-alpha*np.dot(X.transpose(),(X.dot(theta)-y))/m    \n",
    "        cost[i]=computeCost(X, y, theta)\n",
    "    return theta, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, cost = gradientDescent(X, y, theta, alpha, iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03351336687748478"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeCost(X, y, g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作业部分：二、线性回归标准代码(收敛条件判断)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.ones((tem,1))\n",
    "alpha=0.001\n",
    "limit=0.001 #设定收敛极限"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent2(X, y, theta, alpha,limit):\n",
    "   # temp = np.array(np.zeros(theta.shape))\n",
    "  #  parameters = int(theta.ravel().shape[0])\n",
    "    cost_last=computeCost(X, y, theta)\n",
    "    m=y.shape[0]\n",
    "    while True:\n",
    "        theta=theta-alpha*np.dot(X.transpose(),(X.dot(theta)-y))/m    \n",
    "        cost_new=computeCost(X, y, theta)\n",
    "        if np.abs(cost_last/cost_new-1)>limit:\n",
    "           cost_last=cost_new\n",
    "        else:\n",
    "            break\n",
    "    return theta, cost_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, cost = gradientDescent2(X, y, theta, alpha,limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04263270029621483"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeCost(X, y, g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作业部分：三、线性回归标准代码(改变学习率)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.ones((tem,1))\n",
    "alpha=0.005\n",
    "limit=0.001 #设定收敛极限"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent2(X, y, theta, alpha,limit):\n",
    "   # temp = np.array(np.zeros(theta.shape))\n",
    "   # parameters = int(theta.ravel().shape[0])\n",
    "    cost_last=computeCost(X, y, theta)\n",
    "    m=y.shape[0]\n",
    "    while True:\n",
    "        theta=theta-alpha*np.dot(X.transpose(),(X.dot(theta)-y))/m    \n",
    "        cost_new=computeCost(X, y, theta)\n",
    "        if np.abs(cost_last/cost_new-1)>limit:\n",
    "           cost_last=cost_new\n",
    "        else:\n",
    "            break\n",
    "    return theta, cost_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, cost = gradientDescent2(X, y, theta, alpha,limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00012313441318617926"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeCost(X, y, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linearReggresion(object):\n",
    "     def __init__(self,X, y,iter, alpha, limit):\n",
    "         self.X=X\n",
    "         self.y=y\n",
    "         self.iter=iter\n",
    "         self.alpha=alpha\n",
    "         self.limit=limit\n",
    "\n",
    "     def computeCost(self,theta):\n",
    "         m=self.y.shape[0]\n",
    "         thetatem=np.array(theta)\n",
    "         return np.sum((self.X.dot(theta)-self.y)**2)/2/m\n",
    "    \n",
    "     def gradientDescent(self,theta):   \n",
    "         cost = np.zeros(iters)\n",
    "         m=self.y.shape[0]\n",
    "         for i in range(iters):\n",
    "            theta=theta-self.alpha*np.dot(self.X.transpose(),(self.X.dot(theta)-self.y))/m    \n",
    "            cost[i]=computeCost(self.X, self.y, theta)\n",
    "            print(theta[0])\n",
    "         return theta, cost\n",
    "   \n",
    "     def gradientDescent2(self,theta):\n",
    "         cost_last=computeCost(self.X, self.y,theta)\n",
    "         m=y.shape[0]\n",
    "         while True: \n",
    "            theta=theta-self.alpha*np.dot(self.X.transpose(),(self.X.dot(theta)-self.y))/m    \n",
    "            cost_new=computeCost(self.X, self.y, theta)\n",
    "            if np.abs(cost_last/cost_new-1)>self.limit: \n",
    "               cost_last=cost_new  \n",
    "            else:\n",
    "               break  \n",
    "         return theta, cost_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('height_train.csv')\n",
    "# set X (training data) and y (target variable)\n",
    "cols = data.shape[1]\n",
    "X = data.iloc[:,1:cols-1]#X是所有行，去掉最后一列\n",
    "y = data.iloc[:,cols-1:cols]#X是所有行，最后一列\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "tem=int(X.shape[1]+1)\n",
    "X=np.c_[X,np.ones(y.shape[0])]\n",
    "\n",
    "alpha=0.001\n",
    "iters=1000\n",
    "limit=0.001\n",
    "LR=linearReggresion(X,y,iter,alpha,limit)\n",
    "\n",
    "theta = np.ones((tem,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "g,cost = LR.gradientDescent2(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04263270029621483"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.computeCost(g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
